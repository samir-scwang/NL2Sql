# main.py

from dataclasses import dataclass
from langchain.agents import create_agent
from langchain.tools import tool, ToolRuntime
from Nl2Sql import myllm


# å¼•å…¥ DeepSeekï¼ˆä½ è¦çš„è¯­æ³•ï¼‰
deepseek = myllm.deepseek


# --- Context å®šä¹‰ ---
@dataclass
class Context:
    db_name: str


# --- å·¥å…·ï¼šæ‰§è¡Œ SQL æŸ¥è¯¢ ---
@tool
def run_sql(runtime: ToolRuntime[Context], query: str) -> str:
    """æ‰§è¡Œ SQLï¼Œæ¼”ç¤º ToolRuntime çš„ä½¿ç”¨"""

    # ToolRuntime.context
    db = runtime.context.db_name

    # ToolRuntime.streamï¼šè¾“å‡ºæ‰§è¡Œç»†èŠ‚
    writer = runtime.stream_writer

    # Stream custom updates as the tool executes
    writer(f"[SQL Tool] Running on DB: {db}\n")
    # å‡è£…æ‰§è¡Œ SQL
    print(db)
    print(query)
    print(runtime.state)
    print(runtime.context) #Context(db_name='user_db')
    print(runtime.config)
    print(runtime.store)
    return f"[Result from {db}] -> {query}"


# --- åˆ›å»º Agent ---
agent = create_agent(
    model=deepseek,          # DeepSeek åœ¨è¿™é‡Œä½¿ç”¨
    tools=[run_sql],
    context_schema=Context
)


# --- è°ƒç”¨ agent ---
result = agent.invoke(
    {
        "messages": [
            {"role": "user", "content": "æŠŠâ€œè·å–æ‰€æœ‰ç”¨æˆ·çš„åå­—â€è½¬æ¢æˆ SQL å¹¶æ‰§è¡Œã€‚"}
        ]
    },
    context=Context(db_name="user_db")
)

last_msg = result["messages"][-1]
print(last_msg.content)
# inputs = {
#     "messages": [
#         {"role": "user", "content": "æŠŠâ€œè·å–æ‰€æœ‰ç”¨æˆ·çš„åå­—â€è½¬æ¢æˆ SQL å¹¶æ‰§è¡Œã€‚"}
#     ]
# }
#
# for chunk in agent.stream(
#     inputs,
#     context=Context(db_name="user_db"),
#     stream_mode="custom",   # ğŸ‘ˆ å…³é”®
# ):
#     print("STREAM CHUNK:", chunk)